{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment Anything 自定义推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、环境准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.检查 CUDA 状态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多卡需禁用，或者运行后重启内核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def check_cuda():\n",
    "    flag = torch.cuda.is_available()\n",
    "    if flag:\n",
    "        print(\"CUDA可使用\")\n",
    "    else:\n",
    "        print(\"CUDA不可用\")\n",
    "\n",
    "    # 获取GPU数量\n",
    "    ngpu = torch.cuda.device_count()\n",
    "    print(\"GPU数量：\",ngpu)\n",
    "    # Decide which device we want to run on\n",
    "    device = torch.device(\"cuda:1\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "    print(\"驱动为：\",device)\n",
    "    print(\"GPU型号： \",torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "check_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.环境超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "config = Namespace(\n",
    "    img_size=1024,\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    "    model_name=\"vit_b\",\n",
    "    model_cpt_path=\"../checkpoints/sam/sam_vit_b_01ec64.pth\",\n",
    "    random_prompt=False,\n",
    "\n",
    "    mean=(123.675, 116.28, 103.53),\n",
    "    std=(58.395, 57.12, 57.375),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.可视化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))   \n",
    "\n",
    "def trans_ori_comparision(\n",
    "        idxs, images, masks, ori_dataset,\n",
    "        points=None, bboxes=None, cls_labels=None,\n",
    "        mean=None, std=None, max_show_num=1,\n",
    "):\n",
    "    assert images is not None and masks is not None and idxs is not None, \"image, label, id 不可缺少\"\n",
    "    assert max_show_num <= idxs.shape[0], \"展示长度大于图片集长度\"\n",
    "\n",
    "    # tensor -> numpy\n",
    "    idxs = idxs.detach().cpu().numpy()\n",
    "    imgs_arr = images.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
    "    masks_arr = masks.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
    "    masks_arr = masks_arr > 0\n",
    "\n",
    "    if points is not None or bboxes is not None:\n",
    "\n",
    "        cls_labels_arr = cls_labels.detach().cpu().numpy()\n",
    "\n",
    "        if points is not None:\n",
    "            points_arr = points.detach().cpu().numpy()\n",
    "\n",
    "        if bboxes is not None:\n",
    "            bboxs_arr = bboxes.detach().cpu().numpy()\n",
    "\n",
    "    if mean is not None and std is not None:\n",
    "        imgs_arr = (imgs_arr * std + mean).astype(np.uint8)\n",
    "\n",
    "    for i in range(max_show_num):\n",
    "        idx = idxs[i][0]\n",
    "        img_arr = imgs_arr[i]\n",
    "        mask_arr = masks_arr[i].squeeze()\n",
    "\n",
    "        # 创建一个包含两个子图的图形\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "        # 显示第一个图像\n",
    "        axs[0].imshow(img_arr)\n",
    "        axs[0].axis('on')\n",
    "        show_mask(mask_arr, axs[0])\n",
    "\n",
    "        # 显示第二个图像\n",
    "        img_ori, mask_ori, prompt = ori_dataset.get(idx)\n",
    "        img_ori = np.array(img_ori)\n",
    "        mask_ori = np.array(mask_ori) > 0\n",
    "        point_ori = prompt.get('point', None)\n",
    "        bbox_ori = prompt.get('bbox', None)\n",
    "\n",
    "        axs[1].imshow(img_ori)\n",
    "        axs[1].axis('on')\n",
    "        show_mask(mask_ori, axs[1])\n",
    "\n",
    "        # 统一画线\n",
    "        if points is not None or bboxes is not None:\n",
    "            cls_label_arr = cls_labels_arr[i]\n",
    "            if points is not None:\n",
    "                point_arr = points_arr[i]\n",
    "                show_points(point_arr, cls_label_arr, axs[0])\n",
    "                show_points(point_ori, cls_label_arr, axs[1])\n",
    "\n",
    "            if bboxes is not None:\n",
    "                bbox_arr = bboxs_arr[i]\n",
    "                for bbox_1, bbox_2 in zip(bbox_arr, bbox_ori):\n",
    "                    show_box(bbox_1, axs[0])\n",
    "                    show_box(bbox_2, axs[1])\n",
    "\n",
    "        # 显示图形\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry\n",
    "\n",
    "\n",
    "sam = sam_model_registry[config.model_name](checkpoint=config.model_cpt_path)\n",
    "config.img_size = sam.image_encoder.img_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.定义数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.定义数据增强方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "def create_transform():\n",
    "    train_transforms = A.Compose(\n",
    "        [\n",
    "            A.OneOf([\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "            ]),\n",
    "            A.LongestMaxSize(\n",
    "                max_size=config.img_size, p=1.0\n",
    "            ),\n",
    "            A.PadIfNeeded(\n",
    "                min_height=config.img_size, min_width=config.img_size, \n",
    "                border_mode=cv2.BORDER_CONSTANT,\n",
    "                value=0, p=1.0\n",
    "            ),\n",
    "            A.Normalize(\n",
    "                mean=config.mean,\n",
    "                std=config.std,\n",
    "                max_pixel_value=1.0,\n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2(p=1),\n",
    "        ],\n",
    "        p=1.0,\n",
    "        keypoint_params=A.KeypointParams(format='xy'),\n",
    "        bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']),\n",
    "    )\n",
    "    val_transforms = A.Compose(\n",
    "        [\n",
    "            A.LongestMaxSize(\n",
    "                max_size=config.img_size, p=1.0\n",
    "            ),\n",
    "            A.PadIfNeeded(\n",
    "                min_height=config.img_size, min_width=config.img_size, \n",
    "                border_mode=cv2.BORDER_CONSTANT,\n",
    "                value=0, p=1.0\n",
    "            ),\n",
    "            A.Normalize(\n",
    "                mean=config.mean,\n",
    "                std=config.std,\n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2(p=1),\n",
    "        ],\n",
    "        keypoint_params=A.KeypointParams(format='xy'),\n",
    "        bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']),\n",
    "    )\n",
    "    return train_transforms, val_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.定义 dataset 和 dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom.sam.datasets.isic2016 import ISIC2016Dataset\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.utils\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "\n",
    "def create_dataset():\n",
    "    train_imgs = [\n",
    "        str(x) for x in Path(\"/home/zijieshen/new_disk/datasets/ISIC2016/P1/Train\").rglob(\"*.jpg\")\n",
    "        if \"checkpoint\" not in str(x)\n",
    "    ]\n",
    "    val_imgs = [\n",
    "        str(x) for x in Path(\"/home/zijieshen/new_disk/datasets/ISIC2016/P1/Val\").rglob(\"*.jpg\")\n",
    "        if \"checkpoint\" not in str(x)\n",
    "    ]\n",
    "    train_ts, val_ts = create_transform()\n",
    "    train_ds = ISIC2016Dataset(\n",
    "        img_files=train_imgs, transforms=train_ts, \n",
    "        use_bbox=True, use_point=True, use_random=config.random_prompt\n",
    "    )\n",
    "    val_ds = ISIC2016Dataset(\n",
    "        img_files=val_imgs, transforms=val_ts, \n",
    "        use_bbox=True, use_point=True, use_random=False\n",
    "    )\n",
    "    return train_ds, val_ds\n",
    "\n",
    "\n",
    "def create_dataloader(train_ds=None, val_ds=None):\n",
    "    if train_ds is None or val_ds is None:\n",
    "        train_ds, val_ds = create_dataset()\n",
    "\n",
    "    train_dl = DataLoader(\n",
    "        train_ds, batch_size=config.batch_size,\n",
    "        shuffle=True, num_workers=config.num_workers\n",
    "    )\n",
    "    val_dl = DataLoader(\n",
    "        val_ds, batch_size=config.batch_size,\n",
    "        shuffle=False, num_workers=config.num_workers\n",
    "    )\n",
    "    return train_dl, val_dl\n",
    "\n",
    "train_dataset, val_dataset = create_dataset()\n",
    "train_dataloader, val_dataloader = create_dataloader(train_dataset, val_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for batch in train_dataloader:\n",
    "\n",
    "    images = batch.get('image', None)\n",
    "    masks = batch.get('mask', None)\n",
    "    idxs = batch.get('idx', None)\n",
    "\n",
    "    points = batch.get('keypoints', None)\n",
    "    bboxes = batch.get('bboxes', None)\n",
    "    cls_labels = batch.get('cls_labels', None)\n",
    "\n",
    "    trans_ori_comparision(\n",
    "        idxs, images, masks, train_dataset, points, bboxes, cls_labels,\n",
    "        mean=config.mean, std=config.std, max_show_num=1\n",
    "    )\n",
    "   \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.点推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.坐标合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_coords = (points, cls_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    features = sam.image_encoder(images)\n",
    "\n",
    "    sparse_embeddings, dense_embeddings = sam.prompt_encoder(\n",
    "        points=point_coords,\n",
    "        boxes=None,\n",
    "        masks=None\n",
    "    )\n",
    "\n",
    "    low_res_masks, iou_predictions = sam.mask_decoder(\n",
    "        image_embeddings=features,\n",
    "        image_pe=sam.prompt_encoder.get_dense_pe(),\n",
    "        sparse_prompt_embeddings=sparse_embeddings,\n",
    "        dense_prompt_embeddings=dense_embeddings,\n",
    "        multimask_output=False\n",
    "    )\n",
    "\n",
    "    masks = sam.postprocess_masks(\n",
    "        low_res_masks, images.shape[-2:], images.shape[-2:] \n",
    "    )\n",
    "\n",
    "    masks = masks > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_ori_comparision(\n",
    "    idxs, images, masks, train_dataset, points, bboxes, cls_labels,\n",
    "    mean=config.mean, std=config.std, max_show_num=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.框推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    features = sam.image_encoder(images)\n",
    "\n",
    "    sparse_embeddings, dense_embeddings = sam.prompt_encoder(\n",
    "        points=None,\n",
    "        boxes=bboxes,\n",
    "        masks=None\n",
    "    )\n",
    "\n",
    "    low_res_masks, iou_predictions = sam.mask_decoder(\n",
    "        image_embeddings=features,\n",
    "        image_pe=sam.prompt_encoder.get_dense_pe(),\n",
    "        sparse_prompt_embeddings=sparse_embeddings,\n",
    "        dense_prompt_embeddings=dense_embeddings,\n",
    "        multimask_output=False\n",
    "    )\n",
    "\n",
    "    masks = sam.postprocess_masks(\n",
    "        low_res_masks, images.shape[-2:], images.shape[-2:] \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_ori_comparision(\n",
    "    idxs, images, masks, train_dataset, points, bboxes, cls_labels,\n",
    "    mean=config.mean, std=config.std, max_show_num=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySEG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
